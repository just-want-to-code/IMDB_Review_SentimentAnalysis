{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-03T15:27:36.409623Z","iopub.execute_input":"2023-01-03T15:27:36.409980Z","iopub.status.idle":"2023-01-03T15:27:36.451360Z","shell.execute_reply.started":"2023-01-03T15:27:36.409949Z","shell.execute_reply":"2023-01-03T15:27:36.450470Z"},"trusted":true,"id":"VHwxfTZSpyxR","outputId":"aed83d4f-5d3d-4f2d-d0bd-e3fff91b3fb6"},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":["import transformers\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import torch.nn as nn\n","import numpy as np\n","from sklearn import model_selection\n","from sklearn import metrics\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:27:37.890583Z","iopub.execute_input":"2023-01-03T15:27:37.890932Z","iopub.status.idle":"2023-01-03T15:27:37.897180Z","shell.execute_reply.started":"2023-01-03T15:27:37.890904Z","shell.execute_reply":"2023-01-03T15:27:37.895913Z"},"trusted":true,"id":"-OEzR6_3pyxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfx= pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n","dfx.head()"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:36.177036Z","iopub.execute_input":"2023-01-03T15:46:36.177456Z","iopub.status.idle":"2023-01-03T15:46:36.727002Z","shell.execute_reply.started":"2023-01-03T15:46:36.177402Z","shell.execute_reply":"2023-01-03T15:46:36.725986Z"},"trusted":true,"id":"vi7TZYA7pyxb","outputId":"4d379418-6c9a-4f69-9605-0b9a516724e8"},"execution_count":null,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["df_positive= dfx[dfx['sentiment']=='positive'][:12500]\n","df_negative= dfx[dfx['sentiment']=='negative'][:12500]\n","dfx= pd.concat([df_positive,df_negative])\n","len(dfx)"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:48.595199Z","iopub.execute_input":"2023-01-03T15:46:48.595562Z","iopub.status.idle":"2023-01-03T15:46:48.616232Z","shell.execute_reply.started":"2023-01-03T15:46:48.595531Z","shell.execute_reply":"2023-01-03T15:46:48.615403Z"},"trusted":true,"id":"qtePS8Ugpyxc","outputId":"282d75a7-a1cb-44e1-ee95-9489881d3883"},"execution_count":null,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"25000"},"metadata":{}}]},{"cell_type":"code","source":["dfx.sentiment.value_counts()"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:49.795721Z","iopub.execute_input":"2023-01-03T15:46:49.797701Z","iopub.status.idle":"2023-01-03T15:46:49.807313Z","shell.execute_reply.started":"2023-01-03T15:46:49.797654Z","shell.execute_reply":"2023-01-03T15:46:49.806295Z"},"trusted":true,"id":"TP4AGf5hpyxd","outputId":"bc7e472b-dfe6-4fdc-9a75-fc013c15333c"},"execution_count":null,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"positive    12500\nnegative    12500\nName: sentiment, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":["class config:\n","    MAX_LEN = 512\n","    #maximum number of tokens in the sentence\n","    TRAIN_BATCH_SIZE = 8\n","    VALID_BATCH_SIZE = 4\n","    EPOCHS = 5\n","    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    BERT_PATH = \"bert-base-uncased\"\n","    MODEL_PATH = \"model.pth\"\n","    # define the tokenizer\n","    # we use tokenizer and model\n","    # from huggingface's transformers\n","    TOKENIZER = transformers.AutoTokenizer.from_pretrained(BERT_PATH,\n","                                                do_lower_case=True)"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:47:22.083510Z","iopub.execute_input":"2023-01-03T15:47:22.083877Z","iopub.status.idle":"2023-01-03T15:47:26.258298Z","shell.execute_reply.started":"2023-01-03T15:47:22.083850Z","shell.execute_reply":"2023-01-03T15:47:26.257318Z"},"trusted":true,"id":"jPKKYbS7pyxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t=config.TOKENIZER\n","t.is_fast"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:56.111254Z","iopub.execute_input":"2023-01-03T15:46:56.111621Z","iopub.status.idle":"2023-01-03T15:46:56.119283Z","shell.execute_reply.started":"2023-01-03T15:46:56.111585Z","shell.execute_reply":"2023-01-03T15:46:56.117886Z"},"trusted":true,"id":"6vt46Qz-pyxf","outputId":"f11b7cb6-2be5-4d44-af8d-aad2c437c83a"},"execution_count":null,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":["dfx.sentiment = dfx.sentiment.apply(lambda x: 1 if x == \"positive\" else 0)\n","# we split the data into single training\n","# and validation fold\n","df_train, df_valid = model_selection.train_test_split(dfx,\n","                                                      test_size=0.3,\n","                                                      random_state=42,\n","                                                      stratify=dfx.sentiment.values)\n","# reset index\n","df_train = df_train.reset_index(drop=True)\n","df_valid = df_valid.reset_index(drop=True)"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:56.121126Z","iopub.execute_input":"2023-01-03T15:46:56.121545Z","iopub.status.idle":"2023-01-03T15:46:56.148878Z","shell.execute_reply.started":"2023-01-03T15:46:56.121499Z","shell.execute_reply":"2023-01-03T15:46:56.148072Z"},"trusted":true,"id":"ggV1uVkopyxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:56.151086Z","iopub.execute_input":"2023-01-03T15:46:56.151431Z","iopub.status.idle":"2023-01-03T15:46:56.160879Z","shell.execute_reply.started":"2023-01-03T15:46:56.151384Z","shell.execute_reply":"2023-01-03T15:46:56.159997Z"},"trusted":true,"id":"LtkXX9sMpyxi","outputId":"1905b924-aa17-4166-d8e1-15eca7ec847f"},"execution_count":null,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                                              review  sentiment\n0  Unusual film about a man who befriends his soc...          1\n1  Having been a Godzilla fan for many years, Gam...          0\n2  I opted to watch this film for one reason and ...          1\n3  Hello - I normally love movies. I'm 19, I have...          0\n4  Don't listen to most of these people. ill give...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unusual film about a man who befriends his soc...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Having been a Godzilla fan for many years, Gam...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I opted to watch this film for one reason and ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hello - I normally love movies. I'm 19, I have...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Don't listen to most of these people. ill give...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":["import torch\n","class BERTDataset:\n","    def __init__(self, review, target):\n","        \"\"\"\n","        :param review: list or numpy array of strings\n","        :param targets: list or numpy array which is binary\n","        \"\"\"\n","        self.review = review\n","        self.target = target\n","        self.tokenizer = config.TOKENIZER\n","        self.max_len = config.MAX_LEN\n","    def __len__(self):\n","        # this returns the length of dataset\n","        return len(self.review)\n","    def __getitem__(self, item):\n","        # for a given item index, return a dictionary\n","        # of inputs\n","        review = str(self.review[item])\n","        review = \" \".join(review.split())\n","        # here, review is a string\n","        inputs = self.tokenizer.encode_plus(review,\n","                                            add_special_tokens=True,\n","                                            max_length=self.max_len,\n","                                            pad_to_max_length=True,\n","                                            truncation=True)\n","        # ids are ids of tokens generated\n","        # after tokenizing reviews\n","        ids = inputs[\"input_ids\"]\n","        # mask is 1 where we have input\n","        # and 0 where we have padding\n","        mask = inputs[\"attention_mask\"]\n","        # token type ids behave the same way as\n","        # mask in this specific case\n","        # in case of two sentences, this is 0\n","        # for first sentence and 1 for second sentence\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        # now we return everything\n","        # note that ids, mask and token_type_ids\n","        # are all long datatypes and targets is float\n","        return {\n","                \"ids\": torch.tensor(\n","                ids, dtype=torch.long),\n","                \"mask\": torch.tensor(\n","                mask, dtype=torch.long),\n","                \"token_type_ids\": torch.tensor(\n","                token_type_ids, dtype=torch.long),\n","                \"targets\": torch.tensor(\n","                self.target[item], dtype=torch.float)\n","                }"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:56.162423Z","iopub.execute_input":"2023-01-03T15:46:56.163004Z","iopub.status.idle":"2023-01-03T15:46:56.174206Z","shell.execute_reply.started":"2023-01-03T15:46:56.162967Z","shell.execute_reply":"2023-01-03T15:46:56.173232Z"},"trusted":true,"id":"jiVC8J2Cpyxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTBaseUncased(nn.Module):\n","    def __init__(self):\n","        super(BERTBaseUncased, self).__init__()\n","        # we fetch the model from the BERT_PATH \n","        self.bert = transformers.BertModel.from_pretrained(config.BERT_PATH,return_dict=False)\n","        # add a dropout for regularization\n","        self.bert_drop = nn.Dropout(0.3)\n","        # a simple linear layer for output\n","        self.out = nn.Linear(768, 1)\n","    def forward(self, ids, mask, token_type_ids):\n","        # BERT in its default settings returns two outputs\n","        # last hidden state and output of bert pooler layer\n","        # we use the output of the pooler which is of the size\n","        # (batch_size, hidden_size)\n","        # hidden size can be 768 or 1024 depending on\n","        # if we are using bert base or large respectively\n","        # in our case, it is 768\n","        _, o2 = self.bert(ids,\n","                          attention_mask=mask,\n","                          token_type_ids=token_type_ids)\n","        # pass through dropout layer\n","        bo = self.bert_drop(o2)\n","        # pass through linear layer\n","        output = self.out(bo)\n","        # return output\n","        return output"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:56.197234Z","iopub.execute_input":"2023-01-03T15:46:56.198169Z","iopub.status.idle":"2023-01-03T15:46:56.206071Z","shell.execute_reply.started":"2023-01-03T15:46:56.198130Z","shell.execute_reply":"2023-01-03T15:46:56.205180Z"},"trusted":true,"id":"PHkSYOJEpyxl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = BERTDataset(review=df_train.review.values,\n","                                        target=df_train.sentiment.values)\n","# create training dataloader\n","train_data_loader = torch.utils.data.DataLoader(train_dataset,\n","                                                batch_size=config.TRAIN_BATCH_SIZE,\n","                                                num_workers=2)\n","\n","valid_dataset = BERTDataset(review=df_valid.review.values,\n","                                        target=df_valid.sentiment.values)\n","# create validation data loader\n","valid_data_loader = torch.utils.data.DataLoader(valid_dataset,\n","                                                batch_size=config.VALID_BATCH_SIZE,\n","                                                num_workers=1)"],"metadata":{"id":"wonm6k8BqAdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loss_fn(outputs, targets):\n","    \"\"\"\n","    This function returns the loss.\n","    :param outputs: output from the model (real numbers)\n","    :param targets: input targets (binary)\n","    \"\"\"\n","    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n","def train_fn(data_loader, model, optimizer, device, scheduler):\n","    \"\"\"\n","    This is the training function which trains for one epoch\n","    :param data_loader: it is the torch dataloader object\n","    :param model: torch model, bert in our case\n","    :param optimizer: adam, sgd, etc\n","    :param device: can be cpu or cuda\n","    :param scheduler: learning rate scheduler\n","    \"\"\"\n","    # put the model in training mode\n","    model.train()\n","    # loop over all batches\n","    for d in tqdm(data_loader):\n","        # extract ids, token type ids and mask\n","        # from current batch\n","        # also extract targets\n","        ids = d[\"ids\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        mask = d[\"mask\"]\n","        targets = d[\"targets\"]\n","        # move everything to specified device\n","        ids = ids.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets = targets.to(device, dtype=torch.float)\n","        # zero-grad the optimizer\n","        optimizer.zero_grad()\n","        # pass through the model\n","        outputs = model(ids=ids,\n","                        mask=mask,\n","                        token_type_ids=token_type_ids)\n","        # calculate loss\n","        loss = loss_fn(outputs, targets)\n","        # backward step the loss\n","        loss.backward()\n","        # step optimizer\n","        optimizer.step()\n","        # step scheduler\n","        scheduler.step()\n","def eval_fn(data_loader, model, device):\n","    \"\"\"\n","    this is the validation function that generates\n","    predictions on validation data\n","    :param data_loader: it is the torch dataloader object\n","    :param model: torch model, bert in our case\n","    :param device: can be cpu or cuda\n","    :return: output and targets\n","    \"\"\"\n","    # put model in eval mode\n","    model.eval()\n","    # initialize empty lists for\n","    # targets and outputs\n","    fin_targets = []\n","    fin_outputs = []\n","    # use the no_grad scope\n","    # its very important else you might\n","    # run out of gpu memory\n","    with torch.no_grad():\n","        # this part is same as training function\n","        # except for the fact that there is no\n","        # zero_grad of optimizer and there is no loss\n","        # calculation or scheduler steps.\n","        for d in tqdm(data_loader):\n","            ids = d[\"ids\"]\n","            token_type_ids = d[\"token_type_ids\"]\n","            mask = d[\"mask\"]\n","            targets = d[\"targets\"]\n","            ids = ids.to(device, dtype=torch.long)\n","            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","            mask = mask.to(device, dtype=torch.long)\n","            targets = targets.to(device, dtype=torch.float)\n","            outputs = model(ids=ids,\n","                            mask=mask,\n","                            token_type_ids=token_type_ids)\n","            # convert targets to cpu and extend the final list\n","            targets = targets.cpu().detach()\n","            fin_targets.extend(targets.numpy().tolist())\n","            # convert outputs to cpu and extend the final list\n","            outputs = torch.sigmoid(outputs).cpu().detach()\n","            fin_outputs.extend(outputs.numpy().tolist())\n","    return fin_outputs, fin_targets"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:57.262160Z","iopub.execute_input":"2023-01-03T15:46:57.262541Z","iopub.status.idle":"2023-01-03T15:46:57.276935Z","shell.execute_reply.started":"2023-01-03T15:46:57.262507Z","shell.execute_reply":"2023-01-03T15:46:57.275996Z"},"trusted":true,"id":"7XKEleeUpyxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model,device):\n","    # load model and send it to the device\n","    model.to(device)\n","    # create parameters we want to optimize\n","    # we generally dont use any decay for bias\n","    # and weight layers\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [{\n","                                \"params\": [\n","                                p for n, p in param_optimizer if\n","                                not any(nd in n for nd in no_decay)\n","                                ],\n","                                \"weight_decay\": 0.001,\n","                                },\n","                                {\n","                                \"params\": [\n","                                p for n, p in param_optimizer if\n","                                any(nd in n for nd in no_decay)\n","                                ],\n","                                \"weight_decay\": 0.0,\n","                            }]\n","    # calculate the number of training steps\n","    # this is used by scheduler\n","    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n","    # AdamW optimizer\n","    # AdamW is the most widely used optimizer\n","    # for transformer based networks\n","    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n","    # fetch a scheduler\n","    # you can also try using reduce lr on plateau\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=num_train_steps)\n","    # start training the epochs\n","    best_accuracy = 0\n","    for epoch in range(config.EPOCHS):\n","        train_fn(train_data_loader, model, optimizer, device, scheduler)\n","        outputs, targets = eval_fn(valid_data_loader, model, device)\n","        outputs = np.array(outputs) >= 0.5\n","        accuracy = metrics.accuracy_score(targets, outputs)\n","        print(f\"Epoch {epoch}: Accuracy Score = {accuracy}\")\n","        if accuracy > best_accuracy:\n","            torch.save(model.state_dict(), config.MODEL_PATH)\n","            best_accuracy = accuracy"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:58.189340Z","iopub.execute_input":"2023-01-03T15:46:58.189722Z","iopub.status.idle":"2023-01-03T15:46:58.199536Z","shell.execute_reply.started":"2023-01-03T15:46:58.189691Z","shell.execute_reply":"2023-01-03T15:46:58.198339Z"},"trusted":true,"id":"ursr7mycpyxp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BERTBaseUncased()\n","device= config.DEVICE"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:46:58.702492Z","iopub.execute_input":"2023-01-03T15:46:58.703236Z","iopub.status.idle":"2023-01-03T15:47:01.020500Z","shell.execute_reply.started":"2023-01-03T15:46:58.703190Z","shell.execute_reply":"2023-01-03T15:47:01.019497Z"},"trusted":true,"id":"HoR5KMQlpyxp","outputId":"9a6e362f-d61b-4801-a080-2dddc4b3db19"},"execution_count":null,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train(model,device)"],"metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:47:31.407310Z","iopub.execute_input":"2023-01-03T15:47:31.408021Z","iopub.status.idle":"2023-01-03T17:17:53.039459Z","shell.execute_reply.started":"2023-01-03T15:47:31.407981Z","shell.execute_reply":"2023-01-03T17:17:53.038381Z"},"trusted":true,"id":"UC4WwHJspyxq","outputId":"eeff64bd-0fbd-43c3-c261-a1e40f5a14b5"},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 2188/2188 [15:42<00:00,  2.32it/s]\n100%|██████████| 1875/1875 [02:20<00:00, 13.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: Accuracy Score = 0.9165333333333333\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2188/2188 [15:42<00:00,  2.32it/s]\n100%|██████████| 1875/1875 [02:20<00:00, 13.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Accuracy Score = 0.9184\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2188/2188 [15:43<00:00,  2.32it/s]\n100%|██████████| 1875/1875 [02:20<00:00, 13.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Accuracy Score = 0.9229333333333334\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2188/2188 [15:43<00:00,  2.32it/s]\n100%|██████████| 1875/1875 [02:20<00:00, 13.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Accuracy Score = 0.9353333333333333\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2188/2188 [15:43<00:00,  2.32it/s]\n100%|██████████| 1875/1875 [02:20<00:00, 13.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Accuracy Score = 0.9338666666666666\n","output_type":"stream"}]},{"cell_type":"code","source":[],"metadata":{"id":"VWpK_VN-pyxr"},"execution_count":null,"outputs":[]}]}